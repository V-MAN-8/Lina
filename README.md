<img width="1903" height="642" alt="logo" src="https://github.com/user-attachments/assets/d4b6eda8-bb42-4936-b15d-97a33584a6aa" />
Lina  your personal AI model runner that runs locally on your Mac.


### Download open source models in one click,Â all offline, on your Mac. No cloud costs, No data leaks, Just powerful AI Models .

---

### Local AI Model Runner

- Run large language models (LLMs) locally on your Mac
- Complete privacy, all data stays on your device
- No internet required for inference (after model download)
- Powered by llama.cpp for optimized performance

---

### Automatic Dependency Installation

- First launch automatic setup
- Auto downloads and compiles llama.cpp
- No command line use needs

---

### Model Management

- Model Library: Curated collection of suggested models
- Custom Downloads: Add models via Hugging Face URLs
- Multiple Models: Download and switch between different models

---

### Chat Interface

- Multiple Chat Sessions: Create unlimited independent chat conversations
- Session Isolation: Each chat maintains its own context and history
- Chat History Sidebar: Browse, search, and switch between chats
- Real time Streaming: Token-by-token response streaming

---

### File Attachments

- Attach Any Text File: PDFs, code files, documents, markdown, logs, etc.
- Multiple Files: Attach several files at once
- Supported Types: .txt, .md, .py, .js, .swift, .json, .xml, .csv, .log, .pdf, images if the model support Vision

---

### Session Management

- Per Session Isolation: Each chat has its own llama.cpp process
- Independent Contexts: No response bleeding between chats
- Session Persistence: Chat history saved and restored
- Session Switching: Click any chat to resume conversation

---

### Model Library

- Curated Models: Pre selected quality models
- Model Details: Name, size, description for each model
- One Click Download: Simple download from library
- Custom URLs: Add any GGUF model from Hugging Face

---
